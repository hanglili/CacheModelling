{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    \n",
    "    def __init__(self, cache_size):\n",
    "        self.cache = [i for i in range(1, cache_size + 1)]\n",
    "        self.cache_size = cache_size\n",
    "    \n",
    "    def get_element(self, index, remove):\n",
    "        if (index in self.cache):\n",
    "            return True\n",
    "        else:\n",
    "            self.cache.append(index)\n",
    "            if (len(self.cache) > cache_size):\n",
    "                remove(self.cache)\n",
    "            return False\n",
    "    \n",
    "    def get_element_sum(self):\n",
    "        sum = 0\n",
    "        for i in self.cache:\n",
    "            sum += i\n",
    "        return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measure:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.measure_sum = 0.0\n",
    "        self.measure_sum_sq = 0.0\n",
    "        self.n = 0\n",
    "        \n",
    "    def add_observation(self, obs):\n",
    "        self.measure_sum += obs\n",
    "        self.measure_sum_sq += math.pow(obs, 2)\n",
    "        self.n += 1\n",
    "        \n",
    "    def get_num_observations(self):\n",
    "        return self.n\n",
    "    \n",
    "    def sample_mean(self):\n",
    "        return self.measure_sum / self.n\n",
    "    \n",
    "    def sample_variance(self):\n",
    "        return (self.measure_sum_sq - (math.pow(self.measure_sum, 2) / self.n)) / (self.n - 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def t(alpha, gl):\n",
    "        return scipy.stats.t.ppf(1 - (alpha / 2), gl)\n",
    "    \n",
    "    def ci_half_width(self, alpha):\n",
    "        s = math.sqrt(self.sample_variance());\n",
    "        z = Measure.t(alpha, self.n - 1)\n",
    "        return z * s / math.sqrt(self.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp:\n",
    "    \n",
    "  def __init__(self, r):\n",
    "    self.rate = r\n",
    "\n",
    "  def next(self):\n",
    "    return -math.log(random.uniform(0, 1)) / rate\n",
    "\n",
    "  def exp(self, lam):\n",
    "    return -math.log(random.uniform(0, 1)) / lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function pointer for fifo eviction policy\n",
    "def fifo_remove(cache):\n",
    "    cache.pop(0)\n",
    "\n",
    "# Function pointer for random eviction policy\n",
    "def rand_remove(cache):\n",
    "    random_index = random.randrange(len(cache))\n",
    "    cache.pop(random_index)\n",
    "\n",
    "class CacheModellingCT:\n",
    "\n",
    "    # The warm-up is executed when the cache is set up.\n",
    "    def __init__(self, warm_up, population, cache_size, cdf):\n",
    "      self.cache = Cache(cache_size)\n",
    "      self.population = population\n",
    "      self.cdf = cdf\n",
    "      for i in range(warm_up):\n",
    "        self.make_request()\n",
    "\n",
    "    def get_item_index(self, p):\n",
    "      for i in range(self.population):\n",
    "        if (self.cdf[i] >= p):\n",
    "            return i + 1\n",
    "      return self.population\n",
    "\n",
    "    def make_request(self):\n",
    "      p = random.uniform(0, 1)\n",
    "      index = self.get_item_index(p)\n",
    "      return self.cache.get_element(index, rand_remove)\n",
    "\n",
    "    def get_cache_sum(self):\n",
    "        return self.cache.get_element_sum()\n",
    "\n",
    "    # Reset the measures, but not the state - this is useful when\n",
    "    # dividing a single run into batches.\n",
    "    # runLength is the run length of each batch.\n",
    "    def run(self):\n",
    "      return self.make_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_cdf(population):\n",
    "    cdf = []\n",
    "    cumulative = 0.0\n",
    "    sum_of_lambdas = 0.0\n",
    "    for k in range(1, population + 1):\n",
    "        sum_of_lambdas += (1.0 / k)\n",
    "\n",
    "    for k in range(1, population + 1):\n",
    "        prob = (1.0 / k) / sum_of_lambdas\n",
    "        cdf.append(prob + cumulative)\n",
    "        cumulative += prob\n",
    "\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunCacheModellingCT:\n",
    "\n",
    "    def __init__(self, num_batches, num_observations, warm_up, population, cache_size):\n",
    "        self.num_batches = num_batches\n",
    "        self.num_observations = num_observations\n",
    "        self.population = population\n",
    "        self.warm_up = warm_up\n",
    "        self.cache_size = cache_size\n",
    "        self.hit_measure = Measure()\n",
    "        self.miss_rate_measure = Measure()\n",
    "        self.cdf = construct_cdf(population)\n",
    "\n",
    "    def add_to_measures(self, hit_ratio, miss_rate):\n",
    "        self.hit_measure.add_observation(hit_ratio)\n",
    "        self.miss_rate_measure.add_observation(miss_rate)\n",
    "\n",
    "    def display_results(self):\n",
    "        hit_ratio = self.hit_measure.sample_mean()\n",
    "        miss_rate = self.miss_rate_measure.sample_mean()\n",
    "        if (self.num_batches == 1):\n",
    "            print(\"Hit ratio: \" + ('%.4f' % hit_ratio))\n",
    "            print(\"Miss rate: \" + ('%.4f' % miss_rate))\n",
    "        else:\n",
    "            hw_hr = self.hit_measure.ci_half_width(0.05)\n",
    "            hw_mr = self.miss_rate_measure.ci_half_width(0.05)\n",
    "            \n",
    "            lower_ci_hr = hit_ratio - hw_hr\n",
    "            higher_ci_hr = hit_ratio + hw_hr\n",
    "            lower_ci_mr = miss_rate - hw_mr\n",
    "            higher_ci_mr = miss_rate + hw_mr\n",
    "            \n",
    "            print(\"Hit ratio:\", ('%.4f' % hit_ratio),\" CI: (\", ('%.4f' % lower_ci_hr), \",\", ('%.4f' % higher_ci_hr), \")\")\n",
    "            print(\"Miss rate:\", ('%.4f' % miss_rate),\" CI: (\", ('%.4f' % lower_ci_mr), \",\", ('%.4f' % higher_ci_mr), \")\")\n",
    "            \n",
    "    def calculate_miss_rate(self, hit_ratio):\n",
    "        lambda_sum = 0.0\n",
    "        for i in range(1, population + 1):\n",
    "            lambda_sum += (1.0 / i)\n",
    "        return (1 - hit_ratio) * lambda_sum\n",
    "        \n",
    "    # Each run sets up a fresh board.\n",
    "    # There is a separate warm-up for each.\n",
    "    def run_n_times(self):\n",
    "        for i in range(self.num_batches):\n",
    "            cache_modelling = CacheModellingCT(self.warm_up, self.population, self.cache_size, self.cdf)\n",
    "            cur_hit_measure = Measure()\n",
    "            for j in range(self.num_observations):\n",
    "                is_hit = 1.0 if cache_modelling.run() else 0.0\n",
    "                cur_hit_measure.add_observation(is_hit)\n",
    "            \n",
    "            cur_hit_ratio = cur_hit_measure.sample_mean()\n",
    "            cur_miss_rate = self.calculate_miss_rate(cur_hit_ratio)\n",
    "            self.add_to_measures(cur_hit_ratio, cur_miss_rate)\n",
    "        \n",
    "    # Each run resets the measures but doesn't reset the state.\n",
    "    # There is a single warm-up when the board is built.\n",
    "    def run_once(self):\n",
    "        cache_modelling = CacheModellingCT(self.warm_up, self.population, self.cache_size, self.cdf)\n",
    "        for i in range(self.num_batches):\n",
    "            cur_hit_measure = Measure()\n",
    "            for j in range(self.num_observations):\n",
    "                is_hit = 1.0 if cache_modelling.run() else 0.0\n",
    "                cur_hit_measure.add_observation(is_hit)\n",
    "            \n",
    "            cur_hit_ratio = cur_hit_measure.sample_mean()\n",
    "            self.add_to_measures(cur_hit_ratio)\n",
    "    \n",
    "    # Calculate the warm up time by computing the hit ratio of N parallel batches X1, X2, ..., XN at\n",
    "    # each event. Plot this hit ratio (y axis) against nth event (x axis).\n",
    "    def run_plot(self):\n",
    "        max_warm_up = self.num_observations\n",
    "        ith_run = 0\n",
    "        avgs = []\n",
    "        sum_avgs = []\n",
    "        cache_modellings = [CacheModellingCT(0, self.population, self.cache_size, \n",
    "                                             construct_cdf(self.population)) \n",
    "                                             for i in range(self.num_batches)]\n",
    "        while (max_warm_up > ith_run):\n",
    "            cur_hit_measure = Measure()\n",
    "            cur_sum_measure = Measure()\n",
    "            for j in range(self.num_batches):\n",
    "                cache_modelling = cache_modellings[j]\n",
    "                is_hit = 1.0 if cache_modelling.run() else 0.0\n",
    "                cur_hit_measure.add_observation(is_hit)\n",
    "                cur_sum_measure.add_observation(cache_modelling.get_cache_sum())\n",
    "\n",
    "            cur_hit_ratio = cur_hit_measure.sample_mean()\n",
    "            cur_sum_avg = cur_sum_measure.sample_mean()\n",
    "            \n",
    "            avgs.append(cur_hit_ratio)\n",
    "            sum_avgs.append(cur_sum_avg)\n",
    "            \n",
    "            ith_run += 1\n",
    "\n",
    "        return (avgs, sum_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within_epsilon(prev_hit_ratios, cur_hit_ratio, epsilon):\n",
    "    for prev_hit_ratio in prev_hit_ratios:\n",
    "        if (cur_hit_ratio - epsilon > prev_hit_ratio or prev_hit_ratio > cur_hit_ratio + epsilon):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_warm_up_with_parallel_batches(num_batches, population, cache_size):\n",
    "    epsilon = 0.001\n",
    "    max_warm_up = 10000\n",
    "    ith_run = 1\n",
    "    prev_hit_ratios = []\n",
    "    prev_hit_ratios_size = 1\n",
    "    cache_modellings = [CacheModellingCT(0, population, cache_size, construct_cdf(population)) \n",
    "                                         for i in range(num_batches)]\n",
    "    while (max_warm_up > ith_run):\n",
    "        cur_hit_measure = Measure()\n",
    "        for j in range(num_batches):\n",
    "            cache_modelling = cache_modellings[j]\n",
    "            is_hit = 1.0 if cache_modelling.run() else 0.0\n",
    "            cur_hit_measure.add_observation(is_hit)\n",
    "\n",
    "        cur_hit_ratio = cur_hit_measure.sample_mean()\n",
    "        prev_hit_ratios.append(cur_hit_ratio)\n",
    "        \n",
    "        if (len(prev_hit_ratios) == prev_hit_ratios_size):\n",
    "            if (is_within_epsilon(prev_hit_ratios, cur_hit_ratio, epsilon)):\n",
    "                break\n",
    "            else:\n",
    "                prev_hit_ratios.pop(0)\n",
    "        ith_run += 1\n",
    "\n",
    "    return ith_run  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.000 3.000 4.000]\n"
     ]
    }
   ],
   "source": [
    "def moving_average(a, n=100) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "avgs = moving_average([1, 2, 3, 4, 5], 3)\n",
    "np.set_printoptions(formatter={'float': lambda avgs: \"{0:0.3f}\".format(avgs)})\n",
    "print(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within_comparison_range(moving_avgs, index, offset, epsilon):\n",
    "    cur_avg = moving_avgs[index]\n",
    "    for i in range(index - offset, index):\n",
    "        if (moving_avgs[i] - epsilon > cur_avg or cur_avg > moving_avgs[i] + epsilon):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_warm_up_with_moving_avg(num_observations_for_one_batch, population, cache_size):\n",
    "    epsilon = 0.000\n",
    "    run_time = num_observations_for_one_batch\n",
    "    hits = []\n",
    "    cache_modelling = CacheModellingCT(0, population, cache_size, construct_cdf(population))\n",
    "                                        \n",
    "    for i in range(run_time):\n",
    "        is_hit = 1.0 if cache_modelling.run() else 0.0\n",
    "        hits.append(is_hit)      \n",
    "    \n",
    "#     print(hits)\n",
    "    window_size = 1000\n",
    "    moving_avgs = moving_average(hits, window_size)\n",
    "    print(moving_avgs[:1000])\n",
    "    plt.plot(range(len(moving_avgs)), moving_avgs)\n",
    "    \n",
    "#     print(moving_avgs[:100])\n",
    "    comparison_range = 10\n",
    "    for i in range(comparison_range, len(moving_avgs)):\n",
    "        if (is_within_comparison_range(moving_avgs, i, comparison_range, epsilon)):\n",
    "            return i + window_size\n",
    "\n",
    "    return run_time + window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 10000\n",
    "num_observations_for_one_batch = 10000\n",
    "population = 100\n",
    "cache_size = 10\n",
    "# warm_up = 1000 # calculated manually\n",
    "warm_up = calculate_warm_up_with_moving_avg(num_observations_for_one_batch, population, cache_size)\n",
    "print(warm_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = RunCacheModellingCT(num_batches, num_observations_for_one_batch, warm_up, population, cache_size)\n",
    "\n",
    "# sim.run_once()\n",
    "sim.run_n_times()\n",
    "sim.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_and_sum = sim.run_plot()\n",
    "avgs = ratio_and_sum[0]\n",
    "sums = ratio_and_sum[1]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 3))\n",
    "axes[0].plot(range(1, num_observations_for_one_batch + 1), avgs, 'r')\n",
    "axes[1].plot(range(1, num_observations_for_one_batch + 1), sums, 'b')\n",
    "fig.tight_layout()\n",
    "#fig.savefig('rand_50_2500.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
