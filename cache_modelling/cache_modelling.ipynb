{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    \n",
    "    def __init__(self, cache_size):\n",
    "        self.cache = []\n",
    "        self.cache_size = cache_size\n",
    "    \n",
    "    def get_element(self, index, remove):\n",
    "        if (index in self.cache):\n",
    "            return True\n",
    "        else:\n",
    "            self.cache.append(index)\n",
    "            if (len(self.cache) > cache_size):\n",
    "                remove(self.cache)\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measure:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.measure_sum = 0.0\n",
    "        self.measure_sum_sq = 0.0\n",
    "        self.n = 0\n",
    "        \n",
    "    def add_observation(self, obs):\n",
    "        self.measure_sum += obs\n",
    "        self.measure_sum_sq += math.pow(obs, 2)\n",
    "        self.n += 1\n",
    "        \n",
    "    def get_num_observations(self):\n",
    "        return self.n\n",
    "    \n",
    "    def sample_mean(self):\n",
    "        return self.measure_sum / self.n\n",
    "    \n",
    "    def sample_variance(self):\n",
    "        return (self.measure_sum_sq - (math.pow(self.measure_sum, 2) / self.n)) / (self.n - 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def t(alpha, gl):\n",
    "        return scipy.stats.t.ppf(1 - (alpha / 2), gl)\n",
    "    \n",
    "    def ci_half_width(self, alpha):\n",
    "        s = math.sqrt(self.sample_variance());\n",
    "        z = Measure.t(alpha, self.n - 1)\n",
    "        return z * s / math.sqrt(self.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp:\n",
    "    \n",
    "  def __init__(self, r):\n",
    "    self.rate = r\n",
    "\n",
    "  def next(self):\n",
    "    return -math.log(random.uniform(0, 1)) / rate\n",
    "\n",
    "  def exp(self, lam):\n",
    "    return -math.log(random.uniform(0, 1)) / lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function pointer for fifo eviction policy\n",
    "def fifo_remove(cache):\n",
    "    cache.pop(0)\n",
    "\n",
    "# Function pointer for random eviction policy\n",
    "def rand_remove(cache):\n",
    "    random_index = random.randrange(len(cache))\n",
    "    cache.pop(random_index)\n",
    "\n",
    "class CacheModellingCT:\n",
    "\n",
    "    # The warm-up is executed when the cache is set up.\n",
    "    def __init__(self, warm_up, population, cache_size, cdf):\n",
    "      self.cache = Cache(cache_size)\n",
    "      self.population = population\n",
    "      self.cdf = cdf\n",
    "      for i in range(warm_up):\n",
    "        self.make_request()\n",
    "\n",
    "    def get_item_index(self, p):\n",
    "      for i in range(self.population):\n",
    "        if (self.cdf[i] >= p):\n",
    "            return i + 1\n",
    "      return self.population\n",
    "\n",
    "    def make_request(self):\n",
    "      p = random.uniform(0, 1)\n",
    "      index = self.get_item_index(p)\n",
    "      return self.cache.get_element(index, fifo_remove)\n",
    "\n",
    "    # Reset the measures, but not the state - this is useful when\n",
    "    # dividing a single run into batches.\n",
    "    # runLength is the run length of each batch.\n",
    "    def run(self):\n",
    "      return self.make_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_cdf(population):\n",
    "    cdf = []\n",
    "    cumulative = 0.0\n",
    "    sum_of_lambdas = 0.0\n",
    "    for k in range(1, population + 1):\n",
    "        sum_of_lambdas += (1.0 / k)\n",
    "\n",
    "    for k in range(1, population + 1):\n",
    "        prob = (1.0 / k) / sum_of_lambdas\n",
    "        cdf.append(prob + cumulative)\n",
    "        cumulative += prob\n",
    "\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunCacheModellingCT:\n",
    "\n",
    "    def __init__(self, num_batches, num_observations, warm_up, population, cache_size):\n",
    "        self.num_batches = num_batches\n",
    "        self.num_observations = num_observations\n",
    "        self.population = population\n",
    "        self.warm_up = warm_up\n",
    "        self.cache_size = cache_size\n",
    "        self.hit_measure = Measure()\n",
    "        self.cdf = construct_cdf(population)\n",
    "\n",
    "    def add_to_measures(self, hit_ratio):\n",
    "        self.hit_measure.add_observation(hit_ratio)\n",
    "\n",
    "    def display_results(self):\n",
    "        hit_ratio = self.hit_measure.sample_mean()\n",
    "        if (self.num_batches == 1):\n",
    "            print(\"Hit ratio: \" + ('%.4f' % hit_ratio))\n",
    "        else:\n",
    "            hw = self.hit_measure.ci_half_width(0.05)\n",
    "            lower_ci = hit_ratio - hw\n",
    "            higher_ci = hit_ratio + hw\n",
    "            print(\"Hit ratio:\", ('%.4f' % hit_ratio),\" CI: (\", ('%.4f' % lower_ci), \",\", ('%.4f' % higher_ci), \")\")\n",
    "        \n",
    "    # Each run sets up a fresh board.\n",
    "    # There is a separate warm-up for each.\n",
    "    def run_n_times(self):\n",
    "        for i in range(self.num_batches):\n",
    "            cache_modelling = CacheModellingCT(self.warm_up, self.population, self.cache_size, self.cdf)\n",
    "            cur_hit_measure = Measure()\n",
    "            for j in range(self.num_observations):\n",
    "                is_hit = 1.0 if cache_modelling.run() else 0.0\n",
    "                cur_hit_measure.add_observation(is_hit)\n",
    "            \n",
    "            cur_hit_ratio = cur_hit_measure.sample_mean()\n",
    "            self.add_to_measures(cur_hit_ratio)\n",
    "        \n",
    "    # Each run resets the measures but doesn't reset the state.\n",
    "    # There is a single warm-up when the board is built.\n",
    "    def run_once(self):\n",
    "        cache_modelling = CacheModellingCT(self.warm_up, self.population, self.cache_size, self.cdf)\n",
    "        for i in range(self.num_batches):\n",
    "            cur_hit_measure = Measure()\n",
    "            for j in range(self.num_observations):\n",
    "                is_hit = 1.0 if cache_modelling.run() else 0.0\n",
    "                cur_hit_measure.add_observation(is_hit)\n",
    "            \n",
    "            cur_hit_ratio = cur_hit_measure.sample_mean()\n",
    "            self.add_to_measures(cur_hit_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within_epsilon(prev_hit_ratios, cur_hit_ratio, epsilon):\n",
    "    for prev_hit_ratio in prev_hit_ratios:\n",
    "        if (cur_hit_ratio - epsilon > prev_hit_ratio or prev_hit_ratio > cur_hit_ratio + epsilon):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_warm_up(population, cache_size):\n",
    "    epsilon = 0.001\n",
    "    max_warm_up = 100000\n",
    "    window_size = 10\n",
    "    ith_run = 1\n",
    "    prev_hit_ratios = []\n",
    "    prev_hit_ratios_size = 3\n",
    "    cache_modelling = CacheModellingCT(0, population, cache_size, construct_cdf(population))\n",
    "    while (max_warm_up > ith_run):\n",
    "        cur_hit_measure = Measure()\n",
    "        for j in range(window_size):\n",
    "            is_hit = 1.0 if cache_modelling.run() else 0.0\n",
    "            cur_hit_measure.add_observation(is_hit)\n",
    "\n",
    "        cur_hit_ratio = cur_hit_measure.sample_mean()\n",
    "        prev_hit_ratios.append(cur_hit_ratio)\n",
    "        \n",
    "        if (len(prev_hit_ratios) == prev_hit_ratios_size):\n",
    "            if (is_within_epsilon(prev_hit_ratios, cur_hit_ratio, epsilon)):\n",
    "                break\n",
    "            else:\n",
    "                prev_hit_ratios.pop(0)\n",
    "        ith_run += 1\n",
    "\n",
    "    return ith_run\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit ratio: 0.1824  CI: ( 0.1816 , 0.1832 )\n"
     ]
    }
   ],
   "source": [
    "num_batches = 1000\n",
    "num_observations_for_one_batch = 1000\n",
    "population = 1000\n",
    "cache_size = 10\n",
    "warm_up = calculate_warm_up(population, cache_size)\n",
    "sim = RunCacheModellingCT(num_batches, num_observations_for_one_batch, warm_up, population, cache_size)\n",
    "\n",
    "# sim.run_once()\n",
    "sim.run_n_times()\n",
    "sim.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
